{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc036317",
   "metadata": {},
   "source": [
    "# _Main Notebook_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19483fa0",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "\n",
    "- [EDA](#eda)\n",
    "  - [Data Loading](#eda_data)\n",
    "  - [Preliminary checks](#eda_checks)\n",
    "  - [Voting results analysis](#eda_results)\n",
    "  - [Number of votes analysis](#eda_analysis)\n",
    "- [Communities analysis](#communities)\n",
    "  - [Setup](#communities_setup)\n",
    "  - [Interaction Graph](#communites_interaction)\n",
    "  - [Communities](#communities_communities)\n",
    "  - [Vote Analysis](#communities_vote)\n",
    "- [Content of edits analysis](#edits)\n",
    "  - [Setup](#edits_setup)\n",
    "  - [Statistics](#edits_statistics)\n",
    "  - [Investigation of most edited pages](#edits_investigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b85674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from ada2023.utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "from itertools import combinations \n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2535d",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis <a class=\"anchor\" id=\"eda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c00002b",
   "metadata": {},
   "source": [
    "### Data Loading <a class=\"anchor\" id=\"eda_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/wiki-RfA.txt.gz', 'rt', encoding='utf-8') as f:\n",
    "    blocks = f.read().strip().split('\\n\\n')  # Assuming each record is separated by a blank line\n",
    "\n",
    "data = []\n",
    "\n",
    "# Parse each block of text into a dictionary\n",
    "for block in blocks:\n",
    "    record = {}\n",
    "    for line in block.split('\\n'):\n",
    "        if line:\n",
    "            key, value = line.split(':', 1)  # Split on the first colon only\n",
    "            record[key.strip()] = value.strip()\n",
    "    data.append(record)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#Rename the columns\n",
    "df.columns = ['source', 'target', 'vote', 'result', 'year_election', 'date_vote', 'comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose these are your column names and their descriptions\n",
    "data_description = {\n",
    "    'Column Name': ['source', 'target', 'vote', 'result', 'year_election', 'date_vote', 'comment'],\n",
    "    'Description': [\n",
    "        'Voter for the election, identfied by username',\n",
    "        'Candidate for the election, identfied by username',\n",
    "        'Value of the Vote, 0 : neutral, 1 : support, -1 : oppose',\n",
    "        'Result of the election for which vote was cast, 0 : not promoted, 1 : promoted',\n",
    "        'Year of the election',\n",
    "        'Date when the vote was cast',\n",
    "        'Comment associated with the vote'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "data_description_df = pd.DataFrame(data_description)\n",
    "\n",
    "# Create a table figure\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(data_description_df.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[data_description_df['Column Name'], data_description_df['Description']],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "\n",
    "# Update the figure to adjust its size and reduce white space\n",
    "fig.update_layout(\n",
    "    width=500,  # Set the width to your preference\n",
    "    height=350,  # Set the height to your preference\n",
    "    margin=dict(l=10, r=10, t=10, b=40)  # Reduce margins to reduce white space\n",
    ")\n",
    "\n",
    "# Show figure\n",
    "fig.show()\n",
    "\n",
    "#get the html code for the table\n",
    "fig.write_html(\"table.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e1ce2",
   "metadata": {},
   "source": [
    "### Preliminary checks <a class=\"anchor\" id=\"eda_checks\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4463bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe before cleaning the data\n",
    "new_df = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa6d81",
   "metadata": {},
   "source": [
    "##### 1 - Dive into user name source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the source column to string\n",
    "source_cleaned_data = new_df.copy(deep=True)\n",
    "source_cleaned_data['source'] = source_cleaned_data['source'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the distribution of the length of the source tags with a box plot\n",
    "ax = source_cleaned_data['source'].str.len().plot(kind='box', patch_artist=True, \n",
    "                                                  boxprops=dict(facecolor='skyblue'))\n",
    "ax.set_title('Distribution of Length of Source Tags', fontsize=14)\n",
    "ax.set_ylabel('Length of Source Tags', fontsize=14)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85577b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the number of unique source users\n",
    "unique_voters = source_cleaned_data['source'].nunique()\n",
    "print(f'The number of unique voters is {unique_voters}')\n",
    "\n",
    "#Look at the number of null values for the source\n",
    "nan_source = source_cleaned_data[source_cleaned_data.source == '']['source'].count()\n",
    "print(f'The number of voters without tags is {nan_source}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f333a1f",
   "metadata": {},
   "source": [
    "While examining the outliers in relation to their source tags:\n",
    "\n",
    "It's observed that outliers possessing source tags longer than 25 characters typically do not present specific issues.\n",
    "A significant portion of these outliers are identified to have empty source tag lengths. Consequently, we've opted to exclude votes linked with empty source tags. This decision aligns with our objective to utilize the data for community building and to track user interactions. Allowing votes from empty source tags might skew our community analysis, potentially leading to an imbalance where certain users' votes are disproportionately influential compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9fbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the rows with votes associated to empty source \n",
    "source_cleaned_data = source_cleaned_data[source_cleaned_data.source != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b79ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we look at the other outliers, votes with user tags of length greater than 200\n",
    "source_cleaned_data[source_cleaned_data.source.str.len() > 20].source.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f0838",
   "metadata": {},
   "source": [
    "Usernames appear accurate and suitable for user tags, and thus do not require removal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052208fa",
   "metadata": {},
   "source": [
    "##### 2 - Dive into target user name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make deep copy before cleaning for target\n",
    "target_cleaned_data = source_cleaned_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the distribution of the length of the target tags with a box plot\n",
    "ax = target_cleaned_data['target'].str.len().plot(kind='box', patch_artist=True, \n",
    "                                                  boxprops=dict(facecolor='skyblue'))\n",
    "ax.set_title('Distribution of Length of Target Tags', fontsize=14)\n",
    "ax.set_ylabel('Length of Source Tags', fontsize=14)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a286dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the number of unique target users\n",
    "unique_electives = target_cleaned_data['target'].nunique()\n",
    "print(f'The number of unique users running for election is {unique_electives}')\n",
    "\n",
    "#Look at the number of null values for the source\n",
    "nan_target = target_cleaned_data[target_cleaned_data.target == '']['target'].count()\n",
    "print(f'The number of nan values for the target is {nan_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[new_df.target.str.len() > 20].target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e66cf",
   "metadata": {},
   "source": [
    "Usernames appear accurate and suitable for user tags, and thus do not require removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed528dd",
   "metadata": {},
   "source": [
    "##### 3 - Check the date and time of votes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb3c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cleaned_data = target_cleaned_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf22702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract date components\n",
    "def extract_date_components(date_str):\n",
    "    try:\n",
    "        # Split the date string by the comma and space to separate time and date parts\n",
    "        time_part, date_part = date_str.split(', ')\n",
    "        # Split the time part by the colon to separate hours and minutes\n",
    "        hour, minute = time_part.split(':')\n",
    "        # Split the date part by space to separate day, month, and year\n",
    "        day, month, year = date_part.split(' ')\n",
    "        \n",
    "        return pd.Series({\n",
    "            \"hour\": hour,\n",
    "            \"minute\": minute,\n",
    "            \"day\": day,\n",
    "            \"month\": month,\n",
    "            \"year_vote\": year\n",
    "        })\n",
    "    except ValueError:\n",
    "        # If there is a ValueError, return None for each component\n",
    "        return pd.Series({\n",
    "            \"hour\": None,\n",
    "            \"minute\": None,\n",
    "            \"day\": None,\n",
    "            \"month\": None,\n",
    "            \"year_vote\": None\n",
    "        })\n",
    "\n",
    "# Apply the function to each row in the 'date' column\n",
    "date_components = date_cleaned_data['date_vote'].apply(extract_date_components)\n",
    "\n",
    "# Concatenate the new DataFrame with the original one (if needed)\n",
    "date_cleaned_data = pd.concat([date_cleaned_data, date_components], axis=1)\n",
    "\n",
    "date_cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the proportion of rows with missing date_vote\n",
    "non_date_votes = date_cleaned_data[date_cleaned_data.date_vote == ''].date_vote.count()\n",
    "total_count = date_cleaned_data.date_vote.count()\n",
    "print(f'The number of votes for which the date is missing or incorrect is {non_date_votes}')\n",
    "print(f'This represents {(non_date_votes/total_count)*100:.2f}% of the data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the rows with missing date_vote\n",
    "date_cleaned_data = date_cleaned_data[date_cleaned_data.date_vote != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26edafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the distribution for the values of the hour with histogram\n",
    "date_cleaned_data['hour'].value_counts().sort_index().plot(kind='bar' , color = 'teal' ,  edgecolor='black')\n",
    "plt.xlabel('Hour the vote was cast')\n",
    "plt.ylabel('Number of votes cast')\n",
    "# Set a grid for easier reference to the quantities\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.title('Distribution of votes by hour of day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proportion of rows with the hour value as 31\n",
    "ratio_of_31 = date_cleaned_data[date_cleaned_data.hour == \"31\"][\"hour\"].count()/date_cleaned_data[\"hour\"].count()\n",
    "print(f'The proportion of rows with the hour value as 31 is {ratio_of_31}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b6b544",
   "metadata": {},
   "source": [
    "In this dataset, there are a small fraction of votes occurring at the 31st hour, which is not a valid time. Given that the number of occurrences is negligible, we have chosen to exclude this data point from the dataframe. This removal is unlikely to affect the overall analysis of the dataset due to its minimal incidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove from the dataframe the rows with the value of the hour as 31\n",
    "date_cleaned_data = date_cleaned_data[date_cleaned_data['hour'] != '31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e84e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size for better visibility\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "ax = date_cleaned_data['minute'].value_counts().sort_index().plot(kind='bar', color='teal', edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Minute of the hour', fontsize=14)\n",
    "ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "ax.set_title('Distribution of values for the minutes', fontsize=16)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89831b35",
   "metadata": {},
   "source": [
    "The minute values appear to be in order, and their distribution is evenly spread, which aligns with expectations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c08453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the distribution of the values for the days with histogram and order the values\n",
    "\n",
    "ax = date_cleaned_data['day'].value_counts().sort_index().plot(kind='bar' ,  color='teal', edgecolor='black')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Day the vote was cast', fontsize=14)\n",
    "ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "ax.set_title('Distribution of values for the days', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8659464",
   "metadata": {},
   "source": [
    "The values for the day also seem to be correct.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the distribution of the values for the months with histogram and order the values\n",
    "ax = date_cleaned_data['month'].value_counts().sort_index().plot(kind='bar' , color='teal', edgecolor='black')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Month the vote was cast', fontsize=14)\n",
    "ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "ax.set_title('Distribution of values for the months', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b794248",
   "metadata": {},
   "source": [
    "The dataset displays variations in the representation of specific months. For instance, the month of July is listed as 'Jul,' 'Julu,' and 'July'; similarly, October is noted as 'Oct' and 'October.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ad0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map the values of the months to the full name of the month\n",
    "month_map = { \n",
    "    \"Apr\" : \"April\",\n",
    "    \"April\" : \"April\",\n",
    "    \"Aug\" : \"August\",\n",
    "    \"August\" : \"August\",\n",
    "    \"Dec\" : \"December\",\n",
    "    \"December\" : \"December\",\n",
    "    \"Feb\" : \"February\",\n",
    "    \"February\" : \"February\",\n",
    "    \"Jan\" : \"January\",\n",
    "    \"Janry\" : \"January\",\n",
    "    \"January\" : \"January\",\n",
    "    \"Jul\" : \"July\",\n",
    "    \"Julu\" : \"July\",\n",
    "    \"July\" : \"July\",\n",
    "    \"Jun\" : \"June\",\n",
    "    \"June\" : \"June\",\n",
    "    \"Mar\" : \"March\",\n",
    "    \"March\" : \"March\",\n",
    "    \"May\" : \"May\",\n",
    "    \"Mya\" : \"May\",\n",
    "    \"Nov\" : \"November\",\n",
    "    \"November\" : \"November\",\n",
    "    \"Oct\" : \"October\",\n",
    "    \"October\" : \"October\",\n",
    "    \"Sep\" : \"September\",\n",
    "    \"September\" : \"September\"\n",
    "}\n",
    "\n",
    "def correction_month (month) : \n",
    "    return month_map.get(month, month)\n",
    "\n",
    "date_cleaned_data['month'] = date_cleaned_data['month'].apply(correction_month)\n",
    "date_cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3063ff5",
   "metadata": {},
   "source": [
    "The values for the years seems also to be ok.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cleaned_data['date_vote'] = pd.to_datetime(date_cleaned_data['day'].astype(str) + ' ' +\n",
    "                            date_cleaned_data['month'].astype(str) + ' ' +\n",
    "                            date_cleaned_data['year_vote'].astype(str) + ' ' +\n",
    "                            date_cleaned_data['hour'].astype(str) + ':' +\n",
    "                            date_cleaned_data['minute'].astype(str),\n",
    "                            format='%d %B %Y %H:%M' , errors = 'coerce')\n",
    "\n",
    "date_cleaned_data.drop(['hour', 'minute', 'day', 'month', 'year_vote'], axis=1, inplace=True)\n",
    "date_cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2d716c",
   "metadata": {},
   "source": [
    "##### 4 - Dive into the year_election values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_elections_cleaned_data = date_cleaned_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the distribution of the values for year_election\n",
    "year_elections_cleaned_data['year_election'] = year_elections_cleaned_data['year_election'].astype(int)\n",
    "\n",
    "\n",
    "ax = year_elections_cleaned_data['year_election'].value_counts().sort_index().plot(kind='bar' , color='teal', \n",
    "                                                                                   edgecolor='black')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Year the election took place', fontsize=14)\n",
    "ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "ax.set_title('Distribution of the values for year_election', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Ensure the 'year_election' column is of type integer\n",
    "year_elections_cleaned_data['year_election'] = year_elections_cleaned_data['year_election'].astype(str)\n",
    "\n",
    "# Calculate the value counts and sort by index (year)\n",
    "year_election_counts = year_elections_cleaned_data['year_election'].value_counts().sort_index()\n",
    "\n",
    "# Create the bar chart using Plotly\n",
    "fig = px.bar(year_election_counts,\n",
    "             labels={'index': 'Year the election took place', 'value': 'Number of occurrences'},\n",
    "             title='Distribution of the values for year_election')\n",
    "fig.update_layout(xaxis_title='Year the election took place',\n",
    "                  yaxis_title='Number of occurrences',\n",
    "                  yaxis=dict(gridcolor='LightPink', gridwidth=0.5))\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute for each year the proportion of elections in that year over the total number of elections\n",
    "year_elections_cleaned_data['year_election'].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150409e8",
   "metadata": {},
   "source": [
    "##### 5 - Dive into the vote and results values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fb4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_results_data_cleaned = year_elections_cleaned_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2244a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the distribution of the values for the vote\n",
    "vote_results_data_cleaned['vote'] = vote_results_data_cleaned['vote'].astype(int)\n",
    "vote_results_data_cleaned['result'] = vote_results_data_cleaned['result'].astype(int)\n",
    "\n",
    "print(vote_results_data_cleaned['vote'].describe())\n",
    "ax = vote_results_data_cleaned['vote'].value_counts().sort_index().plot(kind='bar' , color='teal', \n",
    "                                                                        edgecolor='black')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Vote', fontsize=14)\n",
    "ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "ax.set_title('Distribution of the values for the votes', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b064cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of each vote value\n",
    "vote_counts = vote_results_data_cleaned['vote'].value_counts(normalize=True) * 100\n",
    "vote_counts = vote_counts.reset_index()\n",
    "vote_counts.columns = ['Vote', 'Percentage']\n",
    "\n",
    "vote_counts['Vote'] = vote_counts['Vote'].astype(str)\n",
    "\n",
    "# Now, create the bar chart using Plotly\n",
    "fig = px.bar(vote_counts, x='Vote', y='Percentage',\n",
    "             labels={'Percentage': 'Percentage (%)', 'Vote': 'Vote'},\n",
    "             title='Percentage Distribution of Vote Values')\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(showlegend=False,\n",
    "                  xaxis_title=\"Vote\",\n",
    "                  yaxis_title=\"Percentage (%)\",\n",
    "                  yaxis=dict(tickformat=\".2f\"))  # Format for two decimal places\n",
    "\n",
    "# To display the plot\n",
    "fig.show()\n",
    "\n",
    "#Save to html\n",
    "fig.write_html(\"vote_percentage.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d25e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_perc_vote = vote_results_data_cleaned['vote'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the percentages\n",
    "print(\"Percentage of Each Unique Value in vote:\")\n",
    "print(value_perc_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4cc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the distribution of the values for the result\n",
    "print(vote_results_data_cleaned['result'].describe())\n",
    "ax = vote_results_data_cleaned['result'].value_counts().sort_index().plot(kind='bar' , color='teal', \n",
    "                                                                          edgecolor='black')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Election result', fontsize=14)\n",
    "ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "ax.set_title('Distribution of the values for the results of the elections', fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_perc_result = vote_results_data_cleaned['result'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the percentages\n",
    "print(\"Percentage of Each Unique Value in result:\")\n",
    "print(value_perc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f3cce",
   "metadata": {},
   "source": [
    "##### 6 - Dive into comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ccc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the proportion of empty comments\n",
    "nb_empty_com = vote_results_data_cleaned[vote_results_data_cleaned.comment == \"\"][\"comment\"].count()\n",
    "ratio_empty_com = nb_empty_com/vote_results_data_cleaned[\"comment\"].count()\n",
    "print(f'The percentage of empty comments is {ratio_empty_com:.2%}%')\n",
    "\n",
    "#Look at the disribution of the length of the comments\n",
    "ax = vote_results_data_cleaned['comment'].str.len().plot(kind='box', patch_artist=True, \n",
    "                                                         boxprops=dict(facecolor='skyblue'))\n",
    "ax.set_title('Distribution of Length of Comments', fontsize=14)\n",
    "ax.set_ylabel('Length of Comments', fontsize=14)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = vote_results_data_cleaned.copy(deep=True)\n",
    "\n",
    "#Store the cleaned dataframe in a csv file\n",
    "cleaned_df.to_csv('../data/wiki-RfA-cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6da031",
   "metadata": {},
   "source": [
    "### Voting results analysis <a class=\"anchor\" id=\"eda_results\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef681ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the cleaned dataframe\n",
    "analysis_df = pd.read_csv('../data/wiki-RfA-cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['date_vote'] = pd.to_datetime(analysis_df['date_vote'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f2ff3",
   "metadata": {},
   "source": [
    "##### 1 - User behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d5db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we plot the distribution of the number of votes per user\n",
    "grouped_per_user = analysis_df.groupby('source').apply(lambda x : pd.Series({\n",
    "    'number_of_votes' : len(x['target'])})).reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = sns.histplot(grouped_per_user['number_of_votes'], color='teal', log=True, bins=1000, edgecolor='black')\n",
    "\n",
    "ax.set_title('Distribution of Number of Votes', fontsize=16)  \n",
    "ax.set_xlabel('Number of Votes', fontsize=14)  \n",
    "ax.set_ylabel('Frequency (Log Scale)', fontsize=14) \n",
    "ax.grid(True) \n",
    "plt.xticks(rotation=45)  \n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descrptive statistics for the number of votes per user\n",
    "grouped_per_user['number_of_votes'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3935480",
   "metadata": {},
   "source": [
    "We can see a classic long-tail distribution of voter activity, indicative of a pattern where a small number of individuals account for a disproportionately large number of votes, while the vast majority participate minimally. The steep decline and subsequent long tail to the right suggest that the community has a few highly engaged users, a common trait in voluntary, community-driven platforms. This could imply that engagement initiatives might focus on the more active users to leverage their influence, or conversely, on the less active majority to increase overall participation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_analysis = analysis_df.groupby('source').apply(lambda x : pd.Series({\n",
    "    'sequence_of_votes' : x['date_vote'].values})).reset_index()\n",
    "\n",
    "def calculation_duration (dates) : \n",
    "     \n",
    "    sorted_dates = sorted(dates)\n",
    "    return (sorted_dates[-1] - sorted_dates[0])\n",
    "\n",
    "date_analysis['duration'] = date_analysis['sequence_of_votes'].apply(calculation_duration)\n",
    "\n",
    "#Look into the distribution of the duration of the sequence of votes\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = sns.histplot(date_analysis['duration'].dt.days, color='teal', log =True,bins = 1000,  edgecolor='black')\n",
    "\n",
    "ax.set_title('Distribution of User Voting Duration', fontsize=15, pad=20)\n",
    "ax.set_xlabel('Duration in Days', fontsize=12)\n",
    "ax.set_ylabel('Frequency (Log Scale)', fontsize=12)\n",
    "ax.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a6796",
   "metadata": {},
   "source": [
    "The histogram depicting the duration between users' first and last votes confirms the conclusion form the previous plot : most users engage in a short burst of activity, casting votes for a brief period before becoming inactive, as shown by the numerous tall bars at the plot's start. This trend aligns with the initial surge of participation seen in the previous plot, where many users voted only a few times. Conversely, the long tail in both plots points to a subset of dedicated users who not only vote more frequently but also stay active over long stretches, suggesting a core group's persistent engagement shapes the platform's voting landscape. Together, these insights reveal a pattern of engagement where a small cohort of users provides ponctual votes and others who have a really important impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for the duration of the sequence of votes\n",
    "date_analysis['duration'].dt.days.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We look at now the distribution of the number of days between two votes for each user\n",
    "def calculation_average_time_between_votes (dates) : \n",
    "    sorted_dates = sorted(dates)\n",
    "    #check division by 0\n",
    "\n",
    "    return (sorted_dates[-1] - sorted_dates[0])/(len(sorted_dates))\n",
    "\n",
    "date_analysis['time_between_votes'] = date_analysis['sequence_of_votes'].apply(calculation_average_time_between_votes)\n",
    "\n",
    "date_analysis['time_between_votes'] = date_analysis['time_between_votes'].apply(lambda x : x.days)\n",
    "\n",
    "date_analysis['time_between_votes'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51be81",
   "metadata": {},
   "source": [
    "##### 2 - Election dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "elect_dynamics_df = analysis_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2758fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set an id fo each of the election following the method used before in order to compute \n",
    "# further statistics regarding the elections\n",
    "\n",
    "# Sort the dataframe by 'target' and 'date_vote'\n",
    "elect_dynamics_df.sort_values(by=['target', 'date_vote'], inplace=True)\n",
    "\n",
    "# Initialize a counter for the global election ID\n",
    "global_election_id = 0\n",
    "# Initialize the last seen election date for each target\n",
    "last_election_date = elect_dynamics_df.groupby('target')['date_vote'].first() - pd.Timedelta(days=8)\n",
    "\n",
    "# Function to assign election ids\n",
    "def assign_election_ids(row):\n",
    "    global global_election_id\n",
    "    # If the current vote date is more than 7 days after the last election date for this target\n",
    "    if (row['date_vote'] - last_election_date[row['target']]).days > 7:\n",
    "        global_election_id += 1\n",
    "        last_election_date[row['target']] = row['date_vote']\n",
    "    return global_election_id\n",
    "\n",
    "# Apply the function to each row\n",
    "elect_dynamics_df['global_election_id'] = elect_dynamics_df.apply(assign_election_ids, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a column corresponding the the index of the vote in the election\n",
    "elect_dynamics_df['vote_index_in_election'] = elect_dynamics_df.groupby(['target', 'global_election_id']).cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56509b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "elect_dynamics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_result(target):\n",
    "    result = elect_dynamics_df[elect_dynamics_df['target'] == target]['result'].unique()\n",
    "    return result[0] if len(result) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_elections_per_user = (elect_dynamics_df.groupby('target')['global_election_id']\n",
    "                                                  .apply(lambda x : len(x.unique()))\n",
    "                                                  .reset_index()\n",
    "                                                  .rename(columns={'global_election_id': 'number_elections'}))\n",
    "                                                  \n",
    "only_one_elections_targets = number_elections_per_user[number_elections_per_user.number_elections == 1]['target'].unique()\n",
    "only_one_election = number_elections_per_user[number_elections_per_user.target.isin(only_one_elections_targets)]\n",
    "\n",
    "only_one_election['result'] = only_one_election['target'].apply(get_unique_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_one = len(only_one_election[only_one_election.result == -1 ]) / len(number_elections_per_user)\n",
    "percentage_one\n",
    "\n",
    "print(f\"The percentage of users with only one election and a negative result is {percentage_one:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the number of elections per user before success \n",
    "#We first filter the dataframe to only keep the targets with at least one successful election\n",
    "\n",
    "targets_with_success = elect_dynamics_df[elect_dynamics_df['result'] == 1].target.unique()\n",
    "elections_with_success = elect_dynamics_df[elect_dynamics_df['target'].isin(targets_with_success)]\n",
    "\n",
    "#We then compute the number of elections per user before success\n",
    "number_elections_before_success_df = (elections_with_success.groupby('target')['global_election_id']\n",
    "                                                  .apply(lambda x : len(x.unique()))\n",
    "                                                  .reset_index()\n",
    "                                                  .rename(columns={'global_election_id': 'number_elections_before_success'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(number_elections_before_success_df, \n",
    "                   x='number_elections_before_success', \n",
    "                   nbins=30,\n",
    "                   color_discrete_sequence=['skyblue'],\n",
    "                   title='Percentage distribution of Estimated Number of Elections Per Target',\n",
    "                   histnorm='percent')\n",
    "fig.update_traces(marker_line_color='black', marker_line_width=1.5)\n",
    "fig.update_layout(xaxis_title='Estimated Number of Elections', yaxis_title='Percentage')\n",
    "fig.show()\n",
    "\n",
    "#Save to html\n",
    "fig.write_html(\"number_elections_per_person.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We compute here different statistics\n",
    "elect_features_df = elect_dynamics_df.groupby(['global_election_id']).apply(lambda x : pd.Series({\n",
    "    'number_of_votes' : len(x['source']), \n",
    "    'ratio_positive_votes' : x[x.vote == 1]['vote'].sum() / len(x.source), \n",
    "    'ratio_neutral_votes' : x[x.vote == 0]['vote'].sum() / len(x.source),\n",
    "    'average_comment_length' : x['comment'].str.len().mean(),\n",
    "    'date_last_vote' : x['date_vote'].max(),\n",
    "    'result' : x['result'].max(),\n",
    "    'year_election' : x['year_election'].max(),\n",
    "    'target' : x['target'].unique(),\n",
    "    'list_of_voters_index_vote ' : x['source'].unique(),\n",
    "    \n",
    "})).reset_index()\n",
    "\n",
    "elect_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c5478",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10)) \n",
    "\n",
    "custom_palette = {1: \"green\", -1: \"red\"}\n",
    "\n",
    "sns.scatterplot(x='date_last_vote',\n",
    "             y='ratio_positive_votes', \n",
    "             hue='result', \n",
    "             style='result', \n",
    "             data=elect_features_df,\n",
    "             palette= custom_palette,\n",
    "             alpha = 0.7) \n",
    "\n",
    "plt.title('Trends in Ratio of Positive Votes by Election Outcome Over Time', fontsize=18)\n",
    "plt.xlabel('Date of Vote', fontsize=16)\n",
    "plt.ylabel('Ratio of Positive Votes', fontsize=16)\n",
    "plt.xticks(rotation=45, fontsize=14)  \n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(title='Election Outcome', fontsize=14, title_fontsize=16)\n",
    "plt.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a556a0a",
   "metadata": {},
   "source": [
    "The scatter plot illustrates a correlation between the ratio of positive votes and election outcomes, with a dense cluster of green dots at higher ratios indicating wins and red dots at lower ratios indicating losses. As the number of votes increases, there seems to be a trend toward more wins, shown by the prevalence of green dots in areas with a greater number of votes. Elections with a moderate ratio of positive votes show a mix of outcomes, reflecting the competitive nature of those elections. Overall, the plot suggests that while a higher number of votes is generally favorable, the ratio of positive votes is a strong indicator of success in elections, as most wins are concentrated in the region with higher positive vote ratios\n",
    "\n",
    "Seems like there is a specific threshold for the percentage of positive votes for an election to be successfull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c664982",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))  \n",
    "\n",
    "sns.scatterplot(x='date_last_vote',\n",
    "             y='number_of_votes', \n",
    "             hue='result', \n",
    "             style='result', \n",
    "             data=elect_features_df,\n",
    "             palette= custom_palette, \n",
    "             alpha = 0.6) \n",
    "\n",
    "plt.title('Trends in Ratio of Number of votes by Election Outcome Over Time', fontsize=18)\n",
    "plt.xlabel('Date of Vote', fontsize=16)\n",
    "plt.ylabel('Number of votes', fontsize=16)\n",
    "plt.xticks(rotation=45, fontsize=14)  \n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(title='Election Outcome', fontsize=14, title_fontsize=16)\n",
    "plt.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862b7bb",
   "metadata": {},
   "source": [
    "The plot suggests that the -1 outcome is commonly associated with a lower number of votes, while the 1 outcome shows greater variability with several outliers indicating exceptionally high vote counts. Despite the presence of both outcomes throughout the time range, there's no apparent temporal trend in voting patterns. We will further analyse this below by loooking at each year and try to detect wether we have further insights. \n",
    "\n",
    "We will use below statistical measure to determine the real relation between the different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We compute the correlation between the ratio of positive votes and the outcome of the election\n",
    "stats.pearsonr(elect_features_df['ratio_positive_votes'], elect_features_df['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We compute the correlation between the number of votes and the outcome of the election\n",
    "stats.pearsonr(elect_features_df['number_of_votes'], elect_features_df['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df = elect_features_df.copy(deep=True)\n",
    "regression_df['result'] = regression_df['result'].replace({-1 : 0})\n",
    "mod = smf.logit(formula='result ~  (year_election) + number_of_votes + ratio_positive_votes + \\\n",
    "                          + ratio_positive_votes + average_comment_length' , data=regression_df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8697b",
   "metadata": {},
   "source": [
    "Model Fit: The R-squared value is 0.8318, which is high, suggesting that the model fits the data well.\n",
    "\n",
    "Significance: The LLR (likelihood ratio test) p-value is less than 0.05, indicating that the model as a whole is statistically significant compared to the null model.\n",
    "\n",
    "Regarding the different coefficients :\n",
    "\n",
    "The ratio_positive_votes coefficient is significant (p < 0.05) and positive, indicating that as the ratio of positive votes increases, the log-odds of winning the election (result=1) significantly increase.\n",
    "The year_election, number_of_votes, and average_comment_length coefficients are not statistically significant (p > 0.05), implying that these variables do not have a significant impact on the log-odds of the election outcome in the presence of other variables.\n",
    "Intercept: The intercept is also not significant, which is not typically a concern as it simply sets the baseline log-odds of the outcome when all predictors are at zero.\n",
    "\n",
    "In summary, the model strongly suggests that the ratio of positive votes is a key predictor of election outcomes, while other variables like the year of the election, the number of votes, and the average comment length do not show a significant relationship in this logistic regression model. The presence of quasi-separation suggests that while the model fits the current data well, it might not generalize well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot the proportion of election that were successful over the years\n",
    "elections_unique_df = elect_features_df.groupby('global_election_id').apply(lambda x : pd.Series({\n",
    "    'result' : x['result'].max(),\n",
    "    'number_voters' : len(x['list_of_voters_index_vote '].values[0]),\n",
    "    'target' : x['target'].values[0],\n",
    "    'year_election' : x['year_election'].max(),\n",
    "})).reset_index()\n",
    "elections_unique_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the distribution of the number of voters per election\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "ax = sns.histplot(elections_unique_df['number_voters'], color='teal', bins=1000, edgecolor='black' )\n",
    "\n",
    "ax.set_title('Distribution of Number of Voters', fontsize=16)\n",
    "\n",
    "ax.set_xlabel('Number of Voters', fontsize=14)\n",
    "ax.set_ylabel('Frequency (Log Scale)', fontsize=14)\n",
    "ax.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_counts = elections_unique_df['result'].value_counts(normalize=True).reset_index()\n",
    "result_counts.columns = ['Election Outcome', 'Percentage']\n",
    "\n",
    "# Converting 'Election Outcome' to string\n",
    "result_counts['Election Outcome'] = result_counts['Election Outcome'].astype(str)\n",
    "\n",
    "# Creating the bar plot using Plotly\n",
    "fig = px.bar(result_counts, \n",
    "             x='Election Outcome', \n",
    "             y='Percentage',\n",
    "             title='Percentage Distribution of Election Outcomes')\n",
    "\n",
    "# Displaying the plot\n",
    "fig.show()\n",
    "\n",
    "# Saving to HTML file\n",
    "fig.write_html(\"election_outcome_percentages.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18088e8",
   "metadata": {},
   "source": [
    "### Number of votes analysis <a class=\"anchor\" id=\"eda_analysis\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5adce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "elect_features_df['year_election'].unique().sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d071d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the distribution of the number of elections per year\n",
    "ax = elect_features_df['year_election'].value_counts().sort_index().plot(kind='bar' , \n",
    "                                                                         color='teal', edgecolor='black')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Year the election took place', fontsize=14)\n",
    "ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c76dcf",
   "metadata": {},
   "source": [
    "We clearly have an imbalance number of elections through the years. We will analyse the trend over time of votting patterns, wether in specific years we had more elections with positiv outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f65a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assuming 'election_year' is of type int\n",
    "for year in sorted(elect_features_df['year_election'].unique()):\n",
    "    data_subset = elect_features_df[elect_features_df['year_election'] == year]\n",
    "    \n",
    "    sns.histplot(x='number_of_votes', data=data_subset, hue='result', log_scale=(False, False), \n",
    "                 color = 'skyblue', edgecolor='black' , palette= 'Set2')\n",
    "    plt.title(f'Histogram for Election Year {int(year)}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ffb1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'number_of_votes', data = elect_features_df , hue = 'result', log_scale= (True, False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3838a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df.groupby([\"target\", \"result\"])[\"source\"].count().median())\n",
    "print(new_df.groupby([\"target\", \"result\"])[\"source\"].count().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6bcea",
   "metadata": {},
   "source": [
    "We have a specific pattern that is quite common every years regarding the elections. We have a high proportion of elections that have a low number of votes and those elections most of the time end with a bad outcome (election being -1). The election that end with a positive outcome tend to rely on an important number of votes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20863f43",
   "metadata": {},
   "source": [
    "# Communities Analysis <a class=\"anchor\" id=\"communities\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582de51",
   "metadata": {},
   "source": [
    "### Setup <a class=\"anchor\" id=\"communities_setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50486b26",
   "metadata": {},
   "source": [
    "We process the Wikipedia Request for Adminship (RfA) dataset into a dataframe. We are using a [Wikipedia edit history dataset](https://snap.stanford.edu/data/wiki-meta.html) containing edit up to january 2008. Therefore we filter votes that aren't present in this timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b09d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/wiki-RfA-cleaned.csv\")\n",
    "\n",
    "# We filter out all the votations after 2008 as we do not have the edits for those dates\n",
    "df = df[df.year_election < 2009]\n",
    "\n",
    "#Set of users that are present in the adminship dataset\n",
    "admin_set = set(df['source'].to_list() + df['target'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98619c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of users present in the adminship dataset : {len(admin_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11fc5b",
   "metadata": {},
   "source": [
    "### Interaction Graph <a class=\"anchor\" id=\"communities_interaction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0355f2d9",
   "metadata": {},
   "source": [
    "We consider an interaction between two users to be an edit from user A in the user talk page of user B. User talk page [\"normal use is for messages from, and discussion with, other editors\"](https://en.wikipedia.org/wiki/Wikipedia:User_pages). We filtered edits to keep only interactions from users that where present in the RfA dataset. Using those interactions we created an undirected graph where the weight is the number of interaction between the two users and each node is a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = create_interaction_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of nodes (users) in the graph : {len(G)}\")\n",
    "print(f\"Number of users in the RfA dataset : {len(admin_set)}\")\n",
    "print(f\"Percentage of users in the graph : {(len(G)/len(admin_set)):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e79d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = df.copy(deep=True)\n",
    "interactions_df['vote'] = interactions_df['vote'].astype(int)\n",
    "\n",
    "def get_interaction_weight(graph, node1, node2):\n",
    "    try:\n",
    "        # Retrieve the weight attribute of the edge between node1 and node2\n",
    "        weight = graph[node1][node2].get('weight', 0)\n",
    "    except KeyError:\n",
    "        # If there's no edge between node1 and node2, the interaction count is 0\n",
    "        weight = 0\n",
    "    return weight\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "interactions_df['interaction_count'] = interactions_df.apply(lambda row: get_interaction_weight(G, row['source'], row['target']), axis=1)\n",
    "\n",
    "interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7687bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the distribution of the number of interactions per election\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "ax = sns.histplot(interactions_df['interaction_count'], color='teal', log=True, bins=1000, edgecolor='black')\n",
    "\n",
    "ax.set_title('Distribution of Number of Interactions', fontsize=16)\n",
    "ax.set_xlabel('Number of Interactions', fontsize=14)\n",
    "ax.set_ylabel('Frequency (Log Scale)', fontsize=14)\n",
    "\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c4b39",
   "metadata": {},
   "source": [
    "We will explore the influence of user interactions, as captured in our interaction graph, on their participation and choices in each other's voting processes. Specifically, we aim to analyze whether interactions between users impact both the likelihood of participating in one another's elections and the eventual voting decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0920e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = []\n",
    "\n",
    "for u, v, data in G.edges(data=True):\n",
    "    weight = data.get('weight', 0)\n",
    "    edge_list.append({'source': u, 'target': v, 'weight': weight})\n",
    "    edge_list.append({'source': v, 'target': u, 'weight': weight})  # Add reverse direction\n",
    "\n",
    "edges_df = pd.DataFrame(edge_list)\n",
    "\n",
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5afc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different filters based on the weight column of edges_df\n",
    "weight_thresholds = np.linspace(5, 60, num= 12, endpoint=True)\n",
    "mean_ratios = []\n",
    "\n",
    "for threshold in weight_thresholds:\n",
    "    # Filter edges_df based on the current threshold\n",
    "    filtered_edges_df = edges_df[edges_df['weight'] >= threshold]\n",
    "    \n",
    "    # Recompute the grouped_interactions DataFrame with the new filter\n",
    "    filtered_grouped_interactions = filtered_edges_df.groupby('target').apply(\n",
    "        lambda x: pd.Series({\n",
    "            'number_of_distinct_interactions': filtered_edges_df[filtered_edges_df['target'] == x.name]['source'].nunique(),\n",
    "            'number_interactors_voting': sum(filtered_edges_df[filtered_edges_df['target'] == x.name]['source'].isin(interactions_df[interactions_df['target'] == x.name]['source']))\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    filtered_grouped_interactions['ratio_interactors_voting'] = filtered_grouped_interactions['number_interactors_voting'] / filtered_grouped_interactions['number_of_distinct_interactions']\n",
    "    mean_ratio = filtered_grouped_interactions['ratio_interactors_voting'].mean()\n",
    "    mean_ratios.append(mean_ratio)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(weight_thresholds, mean_ratios, marker='o')\n",
    "plt.xlabel('Minimum Interaction Weight Threshold')\n",
    "plt.ylabel('Mean Ratio of Interactors Voting')\n",
    "plt.title('Mean Ratio of Interactors Voting by Interaction Weight Threshold')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9df0be",
   "metadata": {},
   "source": [
    "There is a sharp increase in the mean ratio of interactors voting for the target as the minimum interaction weight threshold increases from the lowest value up to a certain point. This suggests that as you consider only those pairs with more significant interactions (a higher weight), there is a higher likelihood that they will participate in each other's elections. This part of the trend indicates a strong positive relationship between interaction intensity and voting participation.\n",
    "The increasing trend in the ratio of voters plateaus, which may imply that beyond a certain point, increasing the threshold for interaction weight does not significantly influence the likelihood of users participating in each other's votes. It can be inferred that there might be a saturation point beyond which the strength of interaction (as quantified by weight) does not have much additional impact on voting participation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = interactions_df.groupby('interaction_count').apply(lambda x: pd.Series({\n",
    "    'proportion_positive_votes': x[x.vote == 1]['vote'].sum() / len(x.source)})).reset_index()\n",
    "grouped\n",
    "\n",
    "# Calculate mean vote for each interaction count\n",
    "# Create a Plotly line plot\n",
    "fig = px.line(grouped, x='interaction_count', y='proportion_positive_votes', markers=True)\n",
    "\n",
    "# Customize the plot\n",
    "fig.update_traces(marker=dict(size=10, line=dict(width=1, color='black')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Percentage of Positive Votes by Number of Interactions',\n",
    "    xaxis_title='Number of Interactions',\n",
    "    yaxis_title='Percentage of Positive Votes',\n",
    "    xaxis=dict(\n",
    "        range=[0, 20],  # Set initial range from 0 to 20\n",
    "        rangeslider=dict(visible=True),  # Enable the rangeslider\n",
    "        type='linear'\n",
    "    ),\n",
    "    title_font_size=20,\n",
    "    font=dict(size=15)\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "#Save the plot to an html file\n",
    "fig.write_html(\"percentage_interactions.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c4adf",
   "metadata": {},
   "source": [
    "Despite the variability, there seems to be a general trend where the percentage of positive votes tends to increase with the number of interactions, especially noticeable in the initial section of the plot. However, this trend is not consistent across the entire range of interaction counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494eb7b2",
   "metadata": {},
   "source": [
    "Here we will implement the logistic regression to analyse the factors that motivate participation following the method described in 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We compute for each voter the number of election he voted for, using elect_dynamics_df\n",
    "elect_dynamics_df['number_of_elections_voted'] = elect_dynamics_df.groupby('source')['global_election_id'].transform('nunique')\n",
    "\n",
    "elect_dynamics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88baa1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_contacts(voter, election, df, edges_df):\n",
    "    list_contacts_voters = edges_df[edges_df['source'] == voter]['target'].values\n",
    "    voter_vote_index = df[(df['source'] == voter) & (df['global_election_id'] == election)]['vote_index_in_election']\n",
    "    \n",
    "    if voter_vote_index.empty:\n",
    "        number_of_contacts = 0\n",
    "    else:\n",
    "        number_of_contacts = df[(df['source'].isin(list_contacts_voters)) & \n",
    "                                (df['global_election_id'] == election) & \n",
    "                                (df['vote_index_in_election'] < voter_vote_index.values[0])\n",
    "                               ]['source'].nunique()\n",
    "\n",
    "    return number_of_contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_interactions (voter, target , edges_df) : \n",
    "    #check wether the voter and the target have interacted before\n",
    "    if edges_df[(edges_df['source'] == voter ) & (edges_df['target'] == target)].empty : \n",
    "        return 0\n",
    "    else : \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to csv \n",
    "elect_dynamics_df.to_csv('/Users/romainberquet/Desktop/epfl/ada/elect_dynamics_df.csv', index=False)\n",
    "edges_df.to_csv('/Users/romainberquet/Desktop/epfl/ada/edges_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f01c81",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "dataset = []\n",
    "\n",
    "# Pre-compute the number of elections each voter has voted in\n",
    "num_elections_voted = elect_dynamics_df.groupby('source')['global_election_id'].nunique()\n",
    "\n",
    "# Get unique voters\n",
    "unique_voters = edges_df['source'].unique()\n",
    "total_voters = len(unique_voters)\n",
    "\n",
    "# Calculate 1% of total voters for progress updates\n",
    "one_percent_voters = total_voters // 100\n",
    "\n",
    "#We iterate over all the voter in the graph\n",
    "for index, voter in tqdm(enumerate(unique_voters)): \n",
    "\n",
    "    # Progress update every 10%\n",
    "    if index % one_percent_voters == 0:\n",
    "        print(f\"Processed {index / total_voters * 100:.0f}% of voters\")\n",
    "\n",
    "    #We iterate over all the elections the voter has voted in\n",
    "    voter_elections = elect_dynamics_df[elect_dynamics_df['source'] == voter]['global_election_id'].unique()\n",
    "    for election in voter_elections: \n",
    "        #Check if the voter has vote_index_in_election > 2 \n",
    "        if elect_dynamics_df[(elect_dynamics_df['source'] == voter) & (elect_dynamics_df['global_election_id'] == election)]['vote_index_in_election'].values[0] > 2:\n",
    "            #We compute the number of elections the voter has voted in\n",
    "            number_of_elections_voted = num_elections_voted[voter]\n",
    "\n",
    "            similar_voters = elect_dynamics_df[\n",
    "                (elect_dynamics_df['number_of_elections_voted'] == number_of_elections_voted) &\n",
    "                (elect_dynamics_df['source'] != voter) &\n",
    "                (~elect_dynamics_df['global_election_id'].eq(election)) \n",
    "            ]['source'].unique()\n",
    "           \n",
    "            if len(similar_voters) > 0:\n",
    "                #Choose a random voter from the similar voters\n",
    "                similar_voter = np.random.choice(similar_voters)\n",
    "\n",
    "                #Get the number of contacts from the voter who voted before the voter\n",
    "                number_contacts_voter_voted_before = get_number_of_contacts(voter, election, elect_dynamics_df, edges_df)\n",
    "                number_contacts_similar_voter_voted_before = get_number_of_contacts(similar_voter, election, elect_dynamics_df, edges_df)\n",
    "\n",
    "                #Get the target of the election\n",
    "                target = elect_dynamics_df[(elect_dynamics_df['source'] == voter) & (elect_dynamics_df['global_election_id'] == election)]['target'].values[0]\n",
    "\n",
    "                dataset.append({\n",
    "                    'voter': voter,\n",
    "                    'voted': 1,\n",
    "                    'number_of_contacts_voter': number_contacts_voter_voted_before - number_contacts_similar_voter_voted_before, \n",
    "                    'number_interactions_voter_candidate': get_number_interactions(voter, target, edges_df)\n",
    "                })\n",
    "                dataset.append({\n",
    "                    'voter': similar_voter,\n",
    "                    'voted': 0,\n",
    "                    'number_of_contacts_voter': number_contacts_similar_voter_voted_before - number_contacts_voter_voted_before, \n",
    "                    'number_interactions_voter_candidate': get_number_interactions(similar_voter, target, edges_df)\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878795ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe from the list of dictionaries\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136bce4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Run a logistic regression on the dataset\n",
    "mod = smf.logit(formula='voted ~ number_of_contacts_voter + number_interactions_voter_candidate', data=dataset_df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the distribution of the number of contacts per voter\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "ax = sns.histplot(dataset_df['number_interactions_voter_candidate'], color='teal', log=True, bins=1000, edgecolor='black')\n",
    "\n",
    "ax.set_title('Distribution of Number of Contacts', fontsize=16)\n",
    "ax.set_xlabel('Number of Contacts', fontsize=14)\n",
    "ax.set_ylabel('Frequency (Log Scale)', fontsize=14)\n",
    "\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72837537",
   "metadata": {},
   "source": [
    "To have a better understanding of the interactions, we plot them in a graph. We also plot the degree rank plot and histogram. The degree of a node is the number of edges adjacents to the node. This plot helps us to better understand the distribution of the number of adjacent nodes. We can see that most of the nodes have a low degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will look into what influences particularly the outcome of a voted\n",
    "dataset = []\n",
    "unique_voters = edges_df['source'].unique()\n",
    "\n",
    "for voter in unique_voters : \n",
    "\n",
    "    voter_elections = elect_dynamics_df[elect_dynamics_df['source'] == voter]['global_election_id'].unique()\n",
    "    #We get the list of the contact of the voter\n",
    "    list_contacts_voters = edges_df[edges_df['source'] == voter]['target'].values\n",
    "\n",
    "    for election in voter_elections :\n",
    "\n",
    "        #Get the vote of the voter in the election \n",
    "        vote = elect_dynamics_df[(elect_dynamics_df['source'] == voter) & (elect_dynamics_df['global_election_id'] == election)]['vote'].values[0]\n",
    "\n",
    "        if list_contacts_voters.size == 0 :\n",
    "            dataset.append({\n",
    "                'voter' : voter,\n",
    "                'number_positive_votes' : 0,\n",
    "                'number_negative_votes' : 0,\n",
    "                'interaction_target_user' :  get_number_interactions(voter, target, edges_df),\n",
    "                'vote' : 0\n",
    "            })\n",
    "\n",
    "        else : \n",
    "    \n",
    "            election_id = elect_dynamics_df[(elect_dynamics_df['source'] == voter) & (elect_dynamics_df['global_election_id'] == election)]['global_election_id'].values[0]\n",
    "            date_vote = elect_dynamics_df[(elect_dynamics_df['source'] == voter) & (elect_dynamics_df['global_election_id'] == election)]['date_vote'].values[0]\n",
    "\n",
    "            #Compute the stats\n",
    "            filtered_iter_df = elect_dynamics_df[(elect_dynamics_df['global_election_id'] == election_id) & \n",
    "                                                (elect_dynamics_df['date_vote'] < date_vote) &\n",
    "                                                (elect_dynamics_df['source'].isin(list_contacts_voters))]\n",
    "            \n",
    "            #Get the number of positive votes\n",
    "            number_positive_votes = filtered_iter_df[filtered_iter_df['vote'] == 1]['vote'].count()\n",
    "\n",
    "            #Get the number of negative votes\n",
    "            number_negative_votes = filtered_iter_df[filtered_iter_df['vote'] == -1]['vote'].count()\n",
    "\n",
    "            \n",
    "            #If the vote is neutral we don't take into account\n",
    "            if vote == 0 : \n",
    "                continue\n",
    "            \n",
    "            #now we add to the dataset the stats \n",
    "            dataset.append({\n",
    "                'voter' : voter,\n",
    "                'number_positive_votes' : number_positive_votes,\n",
    "                'number_negative_votes' : number_negative_votes,\n",
    "                'interaction_target_user' : get_number_interactions(voter, target, edges_df),\n",
    "                'vote' : vote\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame(dataset)\n",
    "dataset_df\n",
    "\n",
    "#change the -1 vote to 0\n",
    "dataset_df['vote'] = dataset_df['vote'].replace({-1 : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a logistic regression on the dataset\n",
    "mod = smf.logit(formula='vote ~ number_positive_votes + number_negative_votes + interaction_target_user', data=dataset_df)\n",
    "\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9709885c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We sort the nodes in the graph by their degree\n",
    "degree_sequence = sorted((d for n, d in G.degree()), reverse=True)\n",
    "unique_degree, counts = np.unique(degree_sequence, return_counts=True)\n",
    "\n",
    "# Degree histogram\n",
    "plt.bar(unique_degree, counts,width=10, color='b')\n",
    "plt.title(\"Degree histogram\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"# of Nodes\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a92ff",
   "metadata": {},
   "source": [
    "### Communities <a class=\"anchor\" id=\"communities_communities\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc515a6",
   "metadata": {},
   "source": [
    "We explore the relationship between users by creating communities. Communities are created using Louvain algorithm that \"[works in 2 steps. On the first step it assigns every node to be in its own community and then for each node it tries to find the maximum positive modularity gain by moving each node to all of its neighbor communities. If no positive gain is achieved the node remains in its original community](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf09d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create the communities\n",
    "\n",
    "communities = nx.community.louvain_communities(G, resolution=1.5, seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b0c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of communities in graph of users with interactions : {len(communities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9cf3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(communities):\n",
    "    print(f\"Community {i} has size {len(c)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a9332",
   "metadata": {},
   "source": [
    "### Vote analysis <a class=\"anchor\" id=\"communities_vote\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f6eeb8",
   "metadata": {},
   "source": [
    "To understand the influence of communities, we compute the probability of vote to be within your community if it was voted at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(G) # Number of nodes in the graph\n",
    "p_same_cluster = 0 # Probability that a random vote is an intra-cluster vote\n",
    "array_p_same_cluster = np.array([])\n",
    "\n",
    "# We compute the probability that a random vote is an intra-cluster vote\n",
    "for c in communities:\n",
    "    p_same_cluster += (len(c)/n)*((len(c)-1)/n)\n",
    "    array_p_same_cluster = np.append(array_p_same_cluster, (len(c)/n)*((len(c)-1)/n))\n",
    "print(f\"Probability that a random vote is an intra-cluster vote in interaction graph : {p_same_cluster:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a counter for votes within the same community\n",
    "intra_vote_count = np.zeros(len(communities))\n",
    "\n",
    "# Iterate through the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    entity1 = row['source']\n",
    "    entity2 = row['target']\n",
    "\n",
    "    # Check if entities are in the same community\n",
    "    for count, community in enumerate(communities):\n",
    "        if entity1 in community and entity2 in community:\n",
    "            intra_vote_count[count] += 1\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of votes within the same community : {int(intra_vote_count.sum())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a422fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a counter for votes in the graph\n",
    "votes_in_the_graph = 0\n",
    "\n",
    "# Iterate through the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    entity1 = row['source']\n",
    "    entity2 = row['target']\n",
    "\n",
    "    # Check if entities are in the graph\n",
    "    if entity1 in G and entity2 in G:\n",
    "        votes_in_the_graph += 1\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of votes in the graph : {votes_in_the_graph}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2380eb",
   "metadata": {},
   "source": [
    "We compare the probability of a random vote with what was observed. The goal is to assess whether the users vote is influenced by its community. We observe that we have a ~3x increase in probability to vote towards your own community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa038ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Effective percentage of intra-cluster votes in G: {(intra_vote_count.sum()/votes_in_the_graph):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3789c",
   "metadata": {},
   "source": [
    "To understand the increase in votes, we compute the expected number of votes if voted at random. Then we make the ratio to derive the multiplicative coefficient from the expected number of votes to observed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected number of intra-cluster votes\n",
    "expected_nb_votes = array_p_same_cluster * votes_in_the_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8befd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of effective intra-cluster votes over expected intra-cluster votes\n",
    "vote_gain = intra_vote_count / expected_nb_votes\n",
    "vote_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d536b7",
   "metadata": {},
   "source": [
    "We want to understand the distribution of votes between communities. For that we plot the distribution of votes between communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a352c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of votes across communities\n",
    "vote_count_matrix = np.zeros((len(communities), len(communities)))\n",
    "nb_community_votes = np.zeros(len(communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the vote count matrix\n",
    "for index, row in df.iterrows():\n",
    "    entity1 = row['source']\n",
    "    entity2 = row['target']\n",
    "    if entity1 in G and entity2 in G:\n",
    "        i_src = find_community(entity1, communities)\n",
    "        i_dst = find_community(entity2, communities)\n",
    "        vote_count_matrix[i_src][i_dst] += 1\n",
    "        nb_community_votes[i_src] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e780189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We verify our computations and transform the vote count matrix into a ratio matrix\n",
    "np.testing.assert_array_equal(vote_count_matrix.sum(axis=1), nb_community_votes)\n",
    "ratio_vote_count_matrix = (vote_count_matrix / nb_community_votes[:, np.newaxis])*100 \n",
    "np.testing.assert_almost_equal(ratio_vote_count_matrix.sum(axis=1), np.ones(len(communities))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5acfb6b",
   "metadata": {},
   "source": [
    "In the plot we observe that the destination communities that recieve most of the votes are the larger communities. This is explained by the fact that for large communities, more votation take place and therefore more votes are directed to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85cbfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Heatmap of the ratio of votes across communities\n",
    "plt.figure(figsize=(24, 12))\n",
    "sns.heatmap(ratio_vote_count_matrix, cmap=\"Blues\", annot=True, fmt=\".1f\", linewidths=.5, linecolor=\"black\")\n",
    "plt.title(\"Percentage of votes per communities in G\")\n",
    "plt.xlabel(\"Destination community\")\n",
    "plt.ylabel(\"Source community\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c235769",
   "metadata": {},
   "source": [
    "To mitigate this domination of the large communities, we scale the results by the probability of a vote between two communities given that the votes are random. We display the ratio of effective votes over expected votes for each pair of communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449253c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix that represents the probability of a vote between two communities\n",
    "prob_vote_community_matrix = np.zeros((len(communities), len(communities)))\n",
    "for i_src in range(len(communities)):\n",
    "    for i_dst in range(len(communities)):\n",
    "        prob_vote_community_matrix[i_src][i_dst] = (len(communities[i_src])*len(communities[i_dst]))/(len(G)**2)\n",
    "# create matrix that represents the expected number of votes between two communities\n",
    "ratio_vote_expected_matrix = prob_vote_community_matrix * votes_in_the_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32348889",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# populate the matrix of votes\n",
    "vote_result_matrix = [[np.zeros(3) for i in range(len(communities))] for j in range(len(communities))]\n",
    "nb_result_votes = np.zeros((len(communities), len(communities)))\n",
    "for index, row in df.iterrows():\n",
    "    entity1 = row['source']\n",
    "    entity2 = row['target']\n",
    "    if entity1 in G and entity2 in G:\n",
    "        i_src = find_community(entity1, communities)\n",
    "        i_dst = find_community(entity2, communities)\n",
    "        if row['vote'] == 1:\n",
    "            vote_result_matrix[i_src][i_dst][2] += 1\n",
    "        elif row['vote'] == -1:\n",
    "            vote_result_matrix[i_src][i_dst][0] += 1\n",
    "        else:\n",
    "            vote_result_matrix[i_src][i_dst][1] += 1\n",
    "        nb_result_votes[i_src][i_dst] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471baa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_vote_expected_matrix = np.nan_to_num(nb_result_votes / ratio_vote_expected_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0853cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the gain from expected votes across communities\n",
    "# Couleurs sympas: 'PuBuGn', 'RdYlBu', 'coolwarm'\n",
    "plt.figure(figsize=(36, 12))\n",
    "sns.heatmap(gain_vote_expected_matrix, cmap='PuBuGn', annot=True, fmt=\".2f\", linewidths=.5, linecolor=\"black\")\n",
    "plt.title(\"Multiplicative relation expected number of votes to observed number of votes per communities in G\")\n",
    "plt.xlabel(\"Destination community\")\n",
    "plt.ylabel(\"Source community\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd1c0c",
   "metadata": {},
   "source": [
    "The diagonal of the matrix has significantly higher values. This indicates that people tend to vote more for the people part of their community. We recall that the communities have been created with the interactions between the users and not the votes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d193e",
   "metadata": {},
   "source": [
    "#### Can we find a rivalry between some communities? Maybe a community only vote negatively towards another community."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec1779",
   "metadata": {},
   "source": [
    "We want to know the voting habitudes of communities. For that we plot the result precentage per community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37eece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate the matrix of votes\n",
    "vote_result_matrix = [[np.zeros(3) for i in range(len(communities))] for j in range(len(communities))]\n",
    "nb_result_votes = np.zeros((len(communities), len(communities)))\n",
    "for index, row in df.iterrows():\n",
    "    entity1 = row['source']\n",
    "    entity2 = row['target']\n",
    "    if entity1 in G and entity2 in G:\n",
    "        i_src = find_community(entity1, communities)\n",
    "        i_dst = find_community(entity2, communities)\n",
    "        if row['vote'] == 1:\n",
    "            vote_result_matrix[i_src][i_dst][2] += 1\n",
    "        elif row['vote'] == -1:\n",
    "            vote_result_matrix[i_src][i_dst][0] += 1\n",
    "        else:\n",
    "            vote_result_matrix[i_src][i_dst][1] += 1\n",
    "        nb_result_votes[i_src][i_dst] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923763e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_result_matrix = np.nan_to_num((vote_result_matrix / nb_result_votes[:,:,np.newaxis]))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72701311",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_ratio_result_matrix = perc_result_matrix[:,:,2]\n",
    "significance_matrix = [[[None]*3 for i in range(len(communities))] for j in range(len(communities))]\n",
    "for i in range(len(communities)):\n",
    "    for j in range(len(communities)):\n",
    "        if int(nb_result_votes[i][j]) != 0:\n",
    "            significance_matrix[i][j][0] = stats.binomtest(int(vote_result_matrix[i][j][2]), \n",
    "                                                         n=int(nb_result_votes[i][j]), \n",
    "                                                         p=value_perc_vote[1]/100,\n",
    "                                                          )\n",
    "plt.figure(figsize=(36, 12))\n",
    "sns.heatmap(for_ratio_result_matrix, cmap=\"Greens\", annot=True, fmt=\".1f\", linewidths=.5, linecolor=\"black\")\n",
    "for i in range(len(communities)):\n",
    "    for j in range(len(communities)):\n",
    "        if significance_matrix[i][j][0]!=None and significance_matrix[i][j][0].pvalue < 0.01:\n",
    "            plt.scatter(j+0.85, i+0.35, color='black', marker='*')\n",
    "plt.title(\"Percentage of votes \\\"for\\\" per communities in G\")\n",
    "plt.xlabel(\"Destination community\")\n",
    "plt.ylabel(\"Source community\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9862998",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_ratio_result_matrix = perc_result_matrix[:,:,1]\n",
    "for i in range(len(communities)):\n",
    "    for j in range(len(communities)):\n",
    "        if int(nb_result_votes[i][j]) != 0:\n",
    "            significance_matrix[i][j][1] = stats.binomtest(int(vote_result_matrix[i][j][1]), \n",
    "                                                         n=int(nb_result_votes[i][j]), \n",
    "                                                         p=value_perc_vote[0]/100)\n",
    "        \n",
    "plt.figure(figsize=(36, 12))\n",
    "sns.heatmap(neutral_ratio_result_matrix, cmap=\"Greys\", annot=True, fmt=\".1f\", linewidths=.5, linecolor=\"black\")\n",
    "for i in range(len(communities)):\n",
    "    for j in range(len(communities)):\n",
    "        if significance_matrix[i][j][1]!=None and significance_matrix[i][j][1].pvalue < 0.01:\n",
    "            plt.scatter(j+0.85, i+0.35, color='black', marker='*')\n",
    "plt.title(\"Percentage of votes \\\"neutral\\\" per communities in G\")\n",
    "plt.xlabel(\"Destination community\")\n",
    "plt.ylabel(\"Source community\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "against_ratio_result_matrix = perc_result_matrix[:,:,0]\n",
    "for i in range(len(communities)):\n",
    "    for j in range(len(communities)):\n",
    "        if int(nb_result_votes[i][j]) != 0:\n",
    "            significance_matrix[i][j][2] = stats.binomtest(int(vote_result_matrix[i][j][0]), \n",
    "                                                         n=int(nb_result_votes[i][j]), \n",
    "                                                         p=value_perc_vote[-1]/100)\n",
    "plt.figure(figsize=(36, 12))\n",
    "sns.heatmap(against_ratio_result_matrix, cmap=\"Reds\", annot=True, fmt=\".1f\", linewidths=.5, linecolor=\"black\")\n",
    "for i in range(len(communities)):\n",
    "    for j in range(len(communities)):\n",
    "        if significance_matrix[i][j][2]!=None and significance_matrix[i][j][2].pvalue < 0.01:\n",
    "            plt.scatter(j+0.85, i+0.35, color='black', marker='*')\n",
    "plt.title(\"Percentage of votes \\\"against\\\" per communities in G\")\n",
    "plt.xlabel(\"Destination community\")\n",
    "plt.ylabel(\"Source community\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f2fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_plot = len(communities)\n",
    "fig, ax = plt.subplots(figsize=(size_plot, size_plot), nrows=len(communities), ncols=len(communities), layout='constrained')\n",
    "for i in range(len(communities)):\n",
    "    for j in range(len(communities)):\n",
    "        diff_for = perc_result_matrix[i][j][2] - value_perc_vote[1]\n",
    "        diff_neutral = perc_result_matrix[i][j][1] - value_perc_vote[0]\n",
    "        diff_against = perc_result_matrix[i][j][0] - value_perc_vote[-1]\n",
    "        ax[i,j].bar(x=['for', 'neutral', 'against'], height=[diff_for, diff_neutral, diff_against], color=['green', 'grey', 'red'])\n",
    "        ax[i,j].set_xticks([])\n",
    "        ax[i,j].set_ylim(-70, 70)\n",
    "        for k in range(3):\n",
    "            if significance_matrix[i][j][k]!=None and significance_matrix[i][j][k].pvalue < 0.01:\n",
    "                ax[i,j].scatter(x=[k], y=[60], marker='*', color='black')\n",
    "\n",
    "for i, ax in enumerate(fig.get_axes()):\n",
    "    if i < len(communities):\n",
    "        ax.set_xlabel(f'{i%len(communities)}', size='large', fontweight='bold') \n",
    "        ax.xaxis.set_label_position('top')\n",
    "    if i%len(communities) == 0 :\n",
    "        ax.set_ylabel(f'{i//len(communities)}', size='large', fontweight='bold')\n",
    "    else :\n",
    "        ax.label_outer()\n",
    "    if i//len(communities) == len(communities)-1:\n",
    "        ax.set_xlabel(f'{i%len(communities)}', size='large', fontweight='bold') \n",
    "fig.suptitle(\"Difference between observed and mean percentage of votes per communities in G\", size='x-large', fontweight='bold')\n",
    "fig.supxlabel(\"Destination community\", size='x-large', fontweight='bold')\n",
    "fig.supylabel(\"Source community\", size='x-large', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69298a",
   "metadata": {},
   "source": [
    "We can observe that some communities display either a positive or negative bias in their voting preferences. If votes were at random and participation uniform accross communities, we would have expected that the portion of votes \"for\", \"against\" and \"neutral\" to have to same proportion between communities. Suspicious results could help us to inspect further the relationship between the two communities involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32282c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gravis as gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_name = [\"Pop Culture Mix\", \"Middle East & Religion\", \"Varied Interests\", \"USA Historical Figures\", \n",
    "              \"Australia\", \"Religion Debates & Controversies\", \"Controversial Pop Culture\", \n",
    "              \"Russia & Eastern Europe\", \"USA & east Asia mix\", \"New Zealand\", \"Military Aircraft\", \"Youth Pop Culture\", \n",
    "              \"India & South Asia\", \"Historical & Political mix\", \"People Mix\", \n",
    "              \"USA Varied Interest\", \"Science\", \"Historical Figures\", \n",
    "              \"UK & Ireland\", \"TV Series 'Lost'\", \"Sports\", \"Scientology\", \n",
    "              \"Canada & Ice Hockey\", \"Comics\", \"Balkans & Central Asia\", \n",
    "              \"Chemical Elements\", \"Wrestling\", \"Oregon\", \"Politics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b6ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for i, c in enumerate(communities):\n",
    "    G.add_node(i)\n",
    "    G.nodes[i]['size'] = len(c)\n",
    "    G.nodes[i]['name'] = communities_name[i]\n",
    "pos = nx.circular_layout(G, scale=700)\n",
    "for i in range(len(communities)):\n",
    "    G.nodes[i]['x'] = pos[i][0]\n",
    "    G.nodes[i]['y'] = pos[i][1]\n",
    "baseline = value_perc_vote[1]\n",
    "for src in range(len(communities)):\n",
    "    for dst in range(len(communities)):\n",
    "        if significance_matrix[src][dst][0]!=None and significance_matrix[src][dst][0].pvalue < 0.01:\n",
    "            ci = significance_matrix[src][dst][0].proportion_ci(confidence_level=0.99)\n",
    "            diff_for = ci.low*100 - baseline if ci.low*100 > baseline  else baseline - ci.high*100\n",
    "            G.add_edge(src,dst, weight=diff_for)\n",
    "            color = \"green\" if ci.low > 0.7 else \"red\"\n",
    "            nx.set_edge_attributes(G, {(src,dst):{\"color\":color}})\n",
    "\n",
    "gv.vis(G, show_menu_toggle_button = False, show_details_toggle_button = False, layout_algorithm_active=False, use_node_size_normalization=True, node_size_normalization_max=60, node_size_normalization_min=7, node_hover_neighborhood=True, node_label_size_factor=2.0, node_label_data_source='name', edge_size_data_source='weight', edge_size_factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132353d",
   "metadata": {},
   "source": [
    "# Content of edits analysis <a class=\"anchor\" id=\"edits\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c01ce",
   "metadata": {},
   "source": [
    "This section explores the relationship between the topics of Wikipedia pages edited by users and the occurrence of votes between two users. The goal is to identify potential correlations and patterns that would show that editing similar topics has an influence in the motivation to cast a vote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4996553f",
   "metadata": {},
   "source": [
    "### Setup <a class=\"anchor\" id=\"edits_setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original dataset can be found here (https://snap.stanford.edu/data/wiki-meta.html). \n",
    "# The version that we use here has already been modified so that we get each user and \n",
    "# the page they modified with the number of edits\n",
    "\n",
    "edits_df = pd.read_csv(\"../data/interactions_edits_grouped.zip\", index_col=0, compression='zip')\n",
    "edits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a list of Wikipedia pages modified by each users\n",
    "user_indices = edits_df.groupby('username').apply(lambda x: x.index.tolist()).reset_index(name='Indices')\n",
    "user_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ebe56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all users present in the edits dataset\n",
    "users = set(edits_df['username'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bd1f9",
   "metadata": {},
   "source": [
    "Create a matrix with the Jaccard index (on the the lists of modified pages) for all pairs of users. Jaccard index \"[is a statistic used for gauging the similarity and diversity of sample sets](https://en.wikipedia.org/wiki/Jaccard_index)\". It will be used to understand the similarity of edited pages between pairs of users."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc63c646",
   "metadata": {},
   "source": [
    "# Initialization of the matrix\n",
    "matrix_similarity = pd.DataFrame(index=list(users), columns=list(users))\n",
    "matrix_similarity"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37dde92e",
   "metadata": {},
   "source": [
    "# Calculate Jaccard index between each pair of users\n",
    "# Takes a few hours to run...\n",
    "for i, user_tuple in enumerate(combinations(list(users), 2)):\n",
    "\n",
    "    pages1 = user_indices[user_indices['username'] == user_tuple[0]]['Indices'].iloc[0]\n",
    "    pages2 = user_indices[user_indices['username'] == user_tuple[1]]['Indices'].iloc[0]\n",
    "    \n",
    "    jaccard_index = jaccard_similarity(set(pages1), set(pages2))\n",
    "\n",
    "    matrix_similarity.at[user_tuple[0], user_tuple[1]] = jaccard_index\n",
    "    matrix_similarity.at[user_tuple[1], user_tuple[0]] = jaccard_index\n",
    "\n",
    "# Fill diagonal with 1 since the Jaccard index with oneself is always 1\n",
    "matrix_similarity = matrix_similarity.fillna(1.0)\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69ce3921",
   "metadata": {},
   "source": [
    "matrix_similarity.to_csv('jaccard.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7dfcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_similarity = pd.read_csv(\"../data/jaccard.csv.zip\", index_col=0, compression='zip')\n",
    "matrix_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef159bb",
   "metadata": {},
   "source": [
    "Create a DataFrame with all pairs of users and a binary variable that indicates if a vote exists for each pair. It will be helpful to computes the correlation between similarity in edited pages and voting interaction between two users."
   ]
  },
  {
   "cell_type": "raw",
   "id": "de410d9d",
   "metadata": {},
   "source": [
    "similarity_and_vote = pd.DataFrame(index=list(combinations(list(users), 2)), columns=['vote', 'jaccard'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "065298a8",
   "metadata": {},
   "source": [
    "# Fill in the new similarity_and_vote with the values from matrix_similarity\n",
    "# Takes 30 minutes to run...\n",
    "for i, index_row in enumerate(similarity_and_vote.iterrows()):\n",
    "    similarity_and_vote.at[index_row[0], 'jaccard'] = matrix_similarity.at[index_row[0][0], index_row[0][1]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2aaaf9f9",
   "metadata": {},
   "source": [
    "# Fill in the new similarity_and_vote with the binary values that indicate the presence of the votes\n",
    "list_users = list(matrix_similarity.index)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if (row['source'] in list_users) & (row['target'] in list_users):\n",
    "        if (row['source'], row['target']) in similarity_and_vote.index:\n",
    "            similarity_and_vote.at[(row['source'], row['target']), 'vote'] = 1\n",
    "        elif (row['target'], row['source']) in similarity_and_vote.index:\n",
    "            similarity_and_vote.at[(row['target'], row['source']), 'vote'] = 1\n",
    "similarity_and_vote = similarity_and_vote.fillna(0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2dc5acdf",
   "metadata": {},
   "source": [
    "similarity_and_vote.to_csv('jaccard_and_votes.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_and_vote = pd.read_csv(\"../data/jaccard_and_votes.csv.zip\", index_col=0, compression='zip')\n",
    "similarity_and_vote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a01a6c",
   "metadata": {},
   "source": [
    "### Statistics <a class=\"anchor\" id=\"edits_statistics\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c9040",
   "metadata": {},
   "source": [
    "Now we will compute some statistics on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a45209",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(similarity_and_vote['vote'], similarity_and_vote['jaccard'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9df37a",
   "metadata": {},
   "source": [
    "The correlation between similarity score on edited pages and the votes is not very strong but positive with high significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean similarity between all pairs of users\n",
    "mean_sim_all = similarity_and_vote['jaccard'].mean()\n",
    "mean_sim_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean similarity between pairs of users that are linked by a vote\n",
    "mean_sim_vote = similarity_and_vote[similarity_and_vote['vote'] == 1]['jaccard'].mean()\n",
    "mean_sim_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac938950",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"People that are linked by a vote have {mean_sim_vote / mean_sim_all:.2f} \"\n",
    "      f\"times more common edited pages than the average.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a02cc",
   "metadata": {},
   "source": [
    "### Investigation of most edited pages <a class=\"anchor\" id=\"edits_investigation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b7775",
   "metadata": {},
   "source": [
    "We investigate most edited pages per community. The goal is to find a common topic that could define community's interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddffbb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for count, community in enumerate(communities):\n",
    "    community_to_check = community\n",
    "    \n",
    "    user_list = list(user_indices['username'])\n",
    "    all_subject = set()\n",
    "    for user in community_to_check:\n",
    "        if user in user_list:\n",
    "            all_subject = (set(user_indices[user_indices['username'] == user]['Indices'].iloc[0])\n",
    "                           .union(all_subject))\n",
    "            \n",
    "    data = pd.DataFrame(index=list(all_subject), columns=['count'])\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    for user in community_to_check:\n",
    "        if user in user_list:\n",
    "            subjects = user_indices[user_indices['username'] == user]['Indices'].iloc[0]\n",
    "            for s in subjects:\n",
    "                data.at[s, 'count'] += 1\n",
    "    print(f\"\\nCommunity {count}:\")            \n",
    "    print(data.sort_values('count', ascending = False).head(20))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
